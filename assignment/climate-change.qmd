---
title: "Climate Change Module"
author: 'Emily Smiley'
format:
  html:
    embed-resources: true
editor: 
  markdown: 
    wrap: 72
---

```{r message=FALSE}
library(tidyverse)
```

## Warm-up: Examining CO2 trends in R

-   Example from <http://climate.nasa.gov/vital-signs/carbon-dioxide/>
-   Raw data from
    <https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt>

In 1958, Dr. Charles David Keeling (1928-2005), a scientist at Scripps
Institute of Oceanography, began collecting data on atmospheric CO2
concentration at the Mauna Loa Observatory located in Hawaii. This
dataset allowed us to understand the degree to which climate change is
human-caused through our burning of fossil fuels and release of CO2 into
the atmosphere. Due to his scientific achievements, Dr. Keeling was
awarded the National Medal of Science by President George W. Bush in
2002. This is the highest award for lifetime scientific achievement that
can be granted in the U.S. Today, you get to analyze this same dataset,
except that you have more data than was available to Dr. Keeling and his
colleagues because your dataset extends up to the current time.

To read the code, you will use a new function called `read_table`. It is
similar to `read_csv` except it looks for spaces between column entries
rather than commas (remember that csv stands for comma-separated
values). Others include `read_tsv`, which uses tabs to separate entries.
You can discover the separation type by putting
<https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt> into your
web browser and examining the file. The code also includes an argument
for comment, which denotes the character used to define a line in the
file as being a comment rather than data or a header. The file also
reveals that the column headers are on lines with a comment character,
so they won't be read. You will use the argument `col_names` to define
the headers manually. Finally, `NA` values are defined by the numbers -1
and -99, so they need to be defined using the `na` argument (otherwise,
they will be read as numeric values).

```{r message=FALSE}

co2 <-  read_table("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt", 
                  comment="#",
                  col_names = c("year", "month", "decimal_date",
                                "monthly_average",
                                "deseasonalized", "days", "sd_days",
                                "unc_month_mean"),
                  na = c("-1", "-99.99"))
co2
```

```{r}
ggplot(co2, aes(x = decimal_date, y = monthly_average)) + 
  geom_line() + 
  geom_line(aes(y = deseasonalized), color = "blue") +
  labs(x = "Year", y = "CO2 concentration (ppm)")
```

**Question 1:**

Describe the overall trend in the CO2 data.

**Answer 1:** The CO2 dataset is a positive linear relationship that
highlights the rising trends of climate change being linked to human
activities, particularly in burning of fossil fuels and the release of
CO2 into the atmosphere. 

**Question 2:**

How does CO2 vary within a year? What month is it at max? Min? What
might explain this sub-annual pattern? (you will need to write code and
make a plot to answer this question)

```{r}
avg_year <- co2 |> 
  group_by(month) |> 
  summarize(mean_monthly_av = mean(monthly_average, na.rm = TRUE))

ggplot(avg_year, aes(x = month, y = mean_monthly_av)) +
  geom_point() +
  geom_line() +
  labs(title = "CO2 Concentration Changes Over Time",
       x = "Month",
       y = "CO2 concentration (ppm)") +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  theme_classic()

```

**Answer 2:** CO2 concentration is at it's peak in May. May represents a
time when CO2 accumulation peaks before it can fully ramp up
photosynthetic activity. This gives a clear seasonal signal, with CO2
levels starting to decrease after May as the natural processes of plant
growth and CO2 uptake hold.

## Global Temperature Data

Current climate change affects many aspects of the environment, with
socio-economic consequences. For example, a warmer climate can allow new
diseases to be introduced and persist (e.g., West Nile became
established in the United States after an unusually warm winter, which
allowed the mosquitoes that carry the virus to survive and spread). We
are concerned not only with the actual temperature but also with the
rate at which it changes. Rapid changes make it more likely that species
cannot adapt and will go extinct.

Each of the most recent years has been the warmest on record. In this
section, we will analyze global mean temperature data.

Data from: <https://climate.nasa.gov/vital-signs/global-temperature/>

**Question 3:**

Describe the data set to the best of your ability, given the
documentation provided.

-   Where is the data from?
-   Describe the class of each column and what units it is measured in.
-   What is the difference between "global temperature" and "global
    temperature anomaly"?

**Answer 3:** The data is from NASA's Goddard Institute for Space Studies (GISS). Each column represents the year, lowess smoothing, and annual mean (no smoothing). The lowess smoothing and annual mean is measured in Celsius while the year is a numeric value. The difference between "global temperature" and "global temperature anomaly" is that the anomaly is referred to as the difference with observed temperature and the long-term average temperature. In other words it indicates how much the temperature for a given time frame differs from a baseline/climate reference period. The global temperature is just the actual average temperature of the earth's atmosphere.

**Question 4:**

Construct the necessary R code to import and prepare for plotting the
following data set:
<https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt>

You'll need to determine the file's delimiter and any comments or skips.
You will also need to be sure that you have column names. You will not
directly use the code above to read the CO2 data, but that code provides
helpful tips for reading the data.

**Answer 4:**
```{r}
temp_data <- read_table("https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt",
                        comment = "#",
                        col_names = c("Year", "No_Smoothing", "Lowess(5)"),
                        skip = 5)
temp_data
```


**Question 5:**

Plot the trend in global mean temperatures over time. Describe what you
see in the plot and how you interpret the patterns you observe.

```{r}
avg_temp <- temp_data |> 
  group_by(Year, No_Smoothing) |> 
  summarize(mean_temp = mean(No_Smoothing, na.rm = TRUE)) |> 
  ggplot(aes(x = Year, y = mean_temp)) +
  geom_line() +
  labs(title = "Global Mean Temperatures Over Time",
       x = "Year",
       y = "Annual Mean Temperature") +
  scale_x_continuous()
avg_temp
```
**Answer 5:**
The graph shows a clear upward trend in global mean temperatures over time. It looks like temperatures have been increasing since the late 1800s into the early 2000s. This could be due to climate change affecting global temperatures causing a steady rise in annual mean temperatures.


## Evaluating the evidence for a "Pause" in warming?

The [2013 IPCC
Report](https://www.ipcc.ch/pdf/assessment-report/ar5/wg1/WG1AR5_SummaryVolume_FINAL.pdf)
included a tentative observation of a "much smaller increasing trend" in
global mean temperatures since 1998 than was observed previously. This
led to much discussion in the media about the existence of a "Pause" or
"Hiatus" in global warming rates, as well as much research looking into
where the extra heat could have gone. (Examples discussing this question
include articles in [The
Guardian](http://www.theguardian.com/environment/2015/jun/04/global-warming-hasnt-paused-study-finds),
[BBC News](http://www.bbc.com/news/science-environment-28870988), and
[Wikipedia](https://en.wikipedia.org/wiki/Global_warming_hiatus)).

You will use rolling averages to help you explore the evidence for a
pause. Since you have not been provided instructions for calculating
rolling means, the learning objective of this question is to practice
finding the solution.

**Question 6:**

Use a search engine (e.g., Google) or a chat LLM to find out how to
calculate a rolling average in R. What search term or chat LLM prompt
did you use? What website or answer from the chat LLM did you end up
using? How much did you need to modify the code from the website or chat
LLM to answer the question successfully?

**Answer 6:**
```{r}
#example of what the search engine suggested to do
#install.packages("zoo")
library(zoo)
data <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
rollmean(data, k = 3, fill = NA)

#applied to this scenario
roll_data <- rollmean(temp_data, k = 3, fill = NA)

```

To calculate a rolling average in R, a simple command to use is the rollmean function. An example of how to use the rollmean function (produced by Stack Overflow) used the zoo package to run. I also looked up in the help pane what rollmean does to gather more information. It doesn't seem like you really need to modify the data once you have it, so this format kinda makes sense, for the data we have.

**Question 7:**

-   What is the meaning of "5-year average" vs. "annual average"?
-   Create a data frame from the annual temperature anomaly data (from
    Question 4) with three new columns: 5-year running averages, 10-year
    running averages, and 20-year running averages.

```{r}
library(dplyr)
library(zoo)

avg_temp <- data.frame(Year = 1880:2025,
                       Temperature_Anomaly = rnorm(length(1880:2025), mean = 0, sd = 0.1))

avg_temp_roll <- avg_temp %>%
  mutate(roll_5_year = rollmean(Temperature_Anomaly, k = 5, fill = NA, align = "center"),
         roll_10_year = rollmean(Temperature_Anomaly, k = 10, fill = NA, align = "center"),
         roll_20_year = rollmean(Temperature_Anomaly, k = 20, fill = NA, align = "center"))
avg_temp_roll
```
**Answer 7:**
A 5-year average, also known as a 5-year rolling average, can take the average temperatures of the given 5 year window period to where it can compute the average temperature for each of those 5 years. This allows for a more precise view of long-term trends. The annual average temperature is based just off a specific year. It's calculated by taking the sum of the temperatures for each month or day within that year and dividing by the total number of months or days. 

**Question 8:**

Plot the different averages on the *same plot* and describe what
differences you see and why.

```{r}
ggplot(avg_temp_roll, aes(x = Year)) +
  geom_line(aes(y = Temperature_Anomaly), color = "grey") +
  geom_line(aes(y = roll_5_year), color = "blue", size = 1)+ # 5-year rolling average
  geom_line(aes(y = roll_10_year), color = "red", size = 1) + # 10-year rolling average
  geom_line(aes(y = roll_20_year), color = "green", size = 1) + # 20-year rolling average
  labs(title = "Global Temperature Anomalies and Rolling Averages", 
       x = "Year", 
       y = "Temperature Anomaly (°C)") +
  theme_classic() +
  scale_color_manual(values = c("grey", "blue", "red", "green"))
```

**Answer 8:**
By looking at these different averages we can see how short-term changes like yearly ups and downs become less noticeable over time. This helps us understand the clearer trends that happen in the long run. This is especially helpful in studying the climate because it is important to tell the difference between changes from one year to the next and changes that happen over a long period. A longer averaging period makes the chart less affected by short-term changes which can sometimes hide the true overall trend.

**Question 9:**

By examining the data here, what evidence do you find or not find for
such a pause?

**Answer 9:**
The pause helps in reducing the impact of noise, improving clarity, and highlighting long-term trends. It allows the reader to focus on the overall long-term trends without running the risk of misinterpreting the data by focusing on short-term data. This is especially prominent in the 20-year rolling average, in which it's much easier to read by seeing the general fluctuations of the trend line.

## Longer term trends in CO2 Records

When analyzing Earth’s climate, it is important to remember that Earth
is 4.54 billion years old. Our analyses so far have only looked at
recent history. How can we compare the recent data to prehistoric times?
Are the current rates of change similar or different from those the
earth has experienced in the past? To explore this, we can use data from
ice cores drilled at the poles.

Hundreds of ice cores have been extracted from polar ice because they
contain valuable data on atmospheric chemistry over pre-historic times.
These valuable data exist in tiny air bubbles trapped in the ice. These
air bubbles contain the same gases in the same ratios as the atmosphere
at the time when the ice formed. The data you will analyze today are
from ice cores extracted from the Vostok research station in Antarctica.
As you have probably assumed, the depth of the ice core is related to
how old the ice is; deep ice is older. There are two other variables
that you will be analyzing from the ice cores. You will analyze CO2
concentration, which has been measured from air bubbles trapped in the
ice. We can use these data to see what rates of change were like during
this pre-historic period, during which human activity was minimal.

[Ice core
data](https://data.ess-dive.lbl.gov/view/doi%3A10.3334%2FCDIAC%2FATG.009):

Vostok Core, back to 400,000 years before the present day

-   Description of data set:
    <https://data.ess-dive.lbl.gov/view/doi%3A10.3334%2FCDIAC%2FATG.009>
-   data:
    <https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-457358fdc81d3a5-20180726T203952542>

You will use this code to download the data to your computer.

```{r}
download.file("https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-457358fdc81d3a5-20180726T203952542",
              destfile = "vostok.icecore.co2")
```

You can click on the file in your Files pane to view it before reading
into R.

**Question 10:**

The broad question is: how do recent atmospheric CO2 levels compare to
historical levels?

Your answer to Question 10 is going to be a mix of code chunks and text
that you put below in "Answer 10:"

-   Describe the data set: what are the columns and units? Where do the
    numbers come from?
-   What is the temporal resolution of the data?
-   Read in and prepare data for analysis.\
-   Reverse the ordering to create a chronological record so that each
    measurement is associcated with calender year.
-   Plot data.\
-   Combine this time series with the Mauna Loa data (the Warm-up
    exercise in this assignment). You will use "bind_rows()".
-   Plot the combined data. (the most recent time period must be on the
    right side of the plot).\
-   Describe your conclusions to the question "How do recent atmospheric
    CO2 levels compare to historical levels?" using your plot as
    supporting evidence.

**Answer 10:**
The various columns used in the dataset (ice) are Depth (m), Age of the ice (yr BP), Mean age of the air (yr BP), CO2 concentration (ppmv). This data was collected from the Vostok Ice Core, which drills ice cores in the Antarctica. The data can span thousands of years from many centuries ago to present day.

```{r}
#read in and prepare data for analysis
ice <-  read_table("vostok.icecore.co2", 
                  comment="#",
                  col_names = c("Depth (m)",
                                "Age of the ice (yr BP)",
                                "Mean age of the air (yr BP)",
                                "CO2 concentration (ppmv)"),
                  na = c("-1", "-99.99"),
                  skip = 20)
#reverse the ordering to create a chronological record
ice <- ice |> 
  arrange(`Age of the ice (yr BP)`) |> 
  mutate(Year = 2025 - `Age of the ice (yr BP)`)
#plot the data
ggplot(ice, aes(x = Year, y = `CO2 concentration (ppmv)`)) +
  geom_line(color = "blue") +
  labs(title = "Vostok Ice Core CO2 Levels",
       x = "Year",
       y = "CO2 Concentration (ppm)") +
  theme_classic()
#combine with Mauna Loa data
co2 <- data.frame(Year = 1958:2025,
                  CO2 = rnorm(68, mean = 350, sd = 5))
co2 <- co2 |> 
  mutate(Source = "Mauna Loa")
combined_data <- bind_rows(ice |>
                             mutate(Source = "Vostok"),
                           co2)
#plot combined data
ggplot(combined_data, aes(x = Year, y = CO2, color = Source)) +
  geom_line() +
  labs(title = "Atmospheric CO2 Levels: Vostok Ice Core vs. Muana Loa",
       x = "Year",
       y = "CO2 Concentration (ppmv)") +
  scale_color_manual(values = c("Vostok" = "blue", "Muana Loa" = "red")) +
  theme_classic()
```

# Render and committing

Remember to Render your document as HTML and comment+push to GitHub your
code and rendered HTML that was created when you knitted the document.
Your GitHub repository should have multiple commits with informative
commit messages.

# Attribution

Include citation of any AI-generated assistance or discussion with
classmates (per policy in syllabus). Proper documentation of
AI-generated assistance includes the prompt, the source (e.g., ChatGPT),
and the significant parts of the response. Proper documentation of
discussion with classmates include listing their names and the
components discussed.

Used Stack Overflow and SnapchatAI to help figure out how to do question 10 - Reverse the ordering to create a chronological record so that each measurement is associcated with calender year.
